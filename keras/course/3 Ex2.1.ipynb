{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_matrix as smplot\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, precision_score, f1_score, zero_one_loss, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/HR_comma_sep.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = df.sales.unique()\n",
    "# categorize jobs column\n",
    "dfjob = pd.get_dummies(df['sales'], prefix='job')\n",
    "df = df.drop('sales', axis=1)\n",
    "df = pd.concat([df, dfjob], axis=1)\n",
    "# categorize salary column\n",
    "dfslry = pd.get_dummies(df['salary'], prefix='salary_level')\n",
    "df = df.drop('salary', axis=1)\n",
    "df = pd.concat([df, dfslry], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffeature = df.drop('left', axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "dffeature.iloc[:,2:5] = ss.fit_transform(dffeature.iloc[:,2:5])\n",
    "\n",
    "X = dffeature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================  20  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[  3.27878050e-01   1.95000057e-01   1.24071661e-01   9.81812308e-02\n",
      "   5.09566149e-02   3.53485973e-02   2.67422105e-02   2.55568736e-02\n",
      "   2.31983493e-02   1.58645338e-02   1.30853374e-02   1.26442883e-02\n",
      "   1.17932476e-02   1.10656420e-02   1.07162373e-02   8.67959679e-03\n",
      "   4.96001542e-03   4.25745676e-03   3.77508942e-33   1.39687060e-33]\n",
      "\n",
      "\n",
      "total variance explained: 1.000\n",
      "\n",
      "\n",
      "========================  19  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[  3.27878050e-01   1.95000057e-01   1.24071661e-01   9.81812308e-02\n",
      "   5.09566149e-02   3.53485973e-02   2.67422105e-02   2.55568736e-02\n",
      "   2.31983493e-02   1.58645338e-02   1.30853374e-02   1.26442883e-02\n",
      "   1.17932476e-02   1.10656420e-02   1.07162373e-02   8.67959679e-03\n",
      "   4.96001542e-03   4.25745676e-03   3.77508942e-33]\n",
      "\n",
      "\n",
      "total variance explained: 1.000\n",
      "\n",
      "\n",
      "========================  18  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429\n",
      "  0.01179325  0.01106564  0.01071624  0.0086796   0.00496002  0.00425746]\n",
      "\n",
      "\n",
      "total variance explained: 1.000\n",
      "\n",
      "\n",
      "========================  17  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429\n",
      "  0.01179325  0.01106564  0.01071624  0.0086796   0.00496002]\n",
      "\n",
      "\n",
      "total variance explained: 0.996\n",
      "\n",
      "\n",
      "========================  16  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429\n",
      "  0.01179325  0.01106564  0.01071624  0.0086796 ]\n",
      "\n",
      "\n",
      "total variance explained: 0.991\n",
      "\n",
      "\n",
      "========================  15  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429\n",
      "  0.01179325  0.01106564  0.01071624]\n",
      "\n",
      "\n",
      "total variance explained: 0.982\n",
      "\n",
      "\n",
      "========================  14  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429\n",
      "  0.01179325  0.01106564]\n",
      "\n",
      "\n",
      "total variance explained: 0.971\n",
      "\n",
      "\n",
      "========================  13  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429\n",
      "  0.01179325]\n",
      "\n",
      "\n",
      "total variance explained: 0.960\n",
      "\n",
      "\n",
      "========================  12  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534  0.01264429]\n",
      "\n",
      "\n",
      "total variance explained: 0.949\n",
      "\n",
      "\n",
      "========================  11  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453  0.01308534]\n",
      "\n",
      "\n",
      "total variance explained: 0.936\n",
      "\n",
      "\n",
      "========================  10  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835  0.01586453]\n",
      "\n",
      "\n",
      "total variance explained: 0.923\n",
      "\n",
      "\n",
      "========================  9  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687  0.02319835]\n",
      "\n",
      "\n",
      "total variance explained: 0.907\n",
      "\n",
      "\n",
      "========================  8  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221  0.02555687]\n",
      "\n",
      "\n",
      "total variance explained: 0.884\n",
      "\n",
      "\n",
      "========================  7  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.0353486\n",
      "  0.02674221]\n",
      "\n",
      "\n",
      "total variance explained: 0.858\n",
      "\n",
      "\n",
      "========================  6  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661  0.03534858]\n",
      "\n",
      "\n",
      "total variance explained: 0.831\n",
      "\n",
      "\n",
      "========================  5  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123  0.05095661]\n",
      "\n",
      "\n",
      "total variance explained: 0.796\n",
      "\n",
      "\n",
      "========================  4  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166  0.09818123]\n",
      "\n",
      "\n",
      "total variance explained: 0.745\n",
      "\n",
      "\n",
      "========================  3  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006  0.12407166]\n",
      "\n",
      "\n",
      "total variance explained: 0.647\n",
      "\n",
      "\n",
      "========================  2  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805  0.19500006]\n",
      "\n",
      "\n",
      "total variance explained: 0.523\n",
      "\n",
      "\n",
      "========================  1  components =========================\n",
      "===== explained variance ratio: ===========================================\n",
      "[ 0.32787805]\n",
      "\n",
      "\n",
      "total variance explained: 0.328\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopping_variance = 0.95 # stopping criteria\n",
    "for n_comps in range(X.shape[1], 0, -1):\n",
    "    pca = PCA(n_components = n_comps)\n",
    "    pca.fit(X)\n",
    "    if sum(pca.explained_variance_ratio_) >= stopping_variance:\n",
    "        pca_sv = pca\n",
    "    \n",
    "    print('======================== ', n_comps, ' components =========================')\n",
    "    print('===== explained variance ratio: ===========================================')\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print('\\n')\n",
    "    print(\"total variance explained: {:0.3f}\".format(sum(pca.explained_variance_ratio_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RunModel(A, B, C, D, model, epos, callbacks=None, cvsplit = 0.0):\n",
    "    history = model.fit(A, B, validation_split = cvsplit, epochs = epos, verbose=0, callbacks = callbacks)\n",
    "\n",
    "#     print('The resulted weights W are: \\n', model.get_weights()[0])\n",
    "#     print('The resulted bias b is: ', model.get_weights()[1])\n",
    "#     print('--------------------------- plot the loss function ------------------------------------')\n",
    "    \n",
    "    N_epo = len(history.history['loss'])\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.plot(np.linspace(1, N_epo, N_epo), history.history['loss'], c='g', label='training set loss')\n",
    "    if cvsplit > 0.:\n",
    "        plt.plot(np.linspace(1, N_epo, N_epo), history.history['val_loss'], c='r', label='CV set loss')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "#     Nticks = N_epo+1 if(N_epo < 40) else 21\n",
    "    plt.xticks(np.linspace(0, N_epo, N_epo+1 if(N_epo < 40) else 21))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print('----------------------------- Accuracy Score ----------------------------------')\n",
    "    print(\"Training set: {:0.3f}\".format(accuracy_score(B, model.predict(A).round())))\n",
    "    print(\"Testing set: {:0.3f}\".format(accuracy_score(D, model.predict(C).round())))\n",
    "    print('----------------------------- Misclassification Rate ----------------------------------')\n",
    "    print(\"Training set: {:0.3f}\".format(zero_one_loss(B, model.predict(A).round())))\n",
    "    print(\"Testing set: {:0.3f}\".format(zero_one_loss(D, model.predict(C).round())))\n",
    "    print('----------------------------- Classification Report ----------------------------------')\n",
    "    print(\"Training set:\", classification_report(B, model.predict(A).round()))\n",
    "    print(\"Testing set:\", classification_report(D, model.predict(C).round()))\n",
    "\n",
    "    plt.scatter(A[:,0], B, c='blue', label='real', alpha=0.8)\n",
    "    plt.scatter(A[:,0], model.predict(A).round(), c='red', label='prediction', alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.left.values\n",
    "X_1pca = pca_sv.transform(X)\n",
    "A, C, B, D = train_test_split(X_1pca, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateDNNModel(input_dim, epos, opt=Adam(lr=0.1), lossfunc = 'binary_crossentropy', metrics = None,\n",
    "                   hidden_nodes=[1], activators = ['sigmoid'], reg=None, verbose=1):\n",
    "    \n",
    "    model = Sequential()\n",
    "    NNlayout = zip(hidden_nodes, activators)\n",
    "    for i_layer, layerparam in enumerate(NNlayout):\n",
    "        if i_layer == 0:\n",
    "            model.add(Dense(layerparam[0], input_dim=input_dim, kernel_regularizer = reg))\n",
    "        else:\n",
    "            model.add(Dense(layerparam[0], kernel_regularizer = reg))\n",
    "        model.add(Activation(layerparam[1]))\n",
    "    if verbose:\n",
    "        print(model.summary())    \n",
    "    model.compile(optimizer = opt, loss = lossfunc, metrics=metrics)\n",
    "#     print('The initial weights W are: \\n', model.get_weights()[0])\n",
    "#     print('The initial bias b is: ', model.get_weights()[1])\n",
    "#     print('---------------------------------------------------------------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use \"CLOSURE\" to pass parameters in the KerasClassifier fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a closure\n",
    "def CreateModel(input_dim, epos, opt=Adam(lr=0.1), lossfunc = 'binary_crossentropy',\n",
    "                metrics = None, hidden_nodes=[1], activators = ['sigmoid'], reg=None, verbose=0):        \n",
    "    def do():\n",
    "        return CreateDNNModel(input_dim, epos, reg=reg, hidden_nodes=hidden_nodes, opt=opt, lossfunc=lossfunc,\n",
    "                              activators=activators, verbose=verbose, metrics=metrics)\n",
    "    return do\n",
    "\n",
    "def KerasCrossVal(A, B, myepos, myreg, myhidden_nodes, myactivators, myopt=Adam(lr=0.1)): \n",
    "    model = KerasClassifier(build_fn=CreateModel(A.shape[1], myepos, reg=myreg, opt=myopt, hidden_nodes=myhidden_nodes, \n",
    "                                                 activators=myactivators, metrics=['accuracy']), \n",
    "                            verbose=0)\n",
    "\n",
    "    scores = cross_val_score(model, A, B, cv = KFold(5, shuffle=True))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90666667,  0.86703704,  0.83259259,  0.78518519,  0.7706558 ])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myepos = 100\n",
    "myreg = l2(0.01)\n",
    "myhidden_nodes=[20, 1]\n",
    "myactivators = ['relu','sigmoid']\n",
    "KerasCrossVal(A, B, myepos, myreg, myhidden_nodes, myactivators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use Cross Validation to find the best parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= tested DNN with layers :  [5, 1] ==================\n",
      "The cross validation accuracy is 0.8598 ± 0.0446\n",
      "================= tested DNN with layers :  [10, 1] ==================\n",
      "The cross validation accuracy is 0.8587 ± 0.0243\n"
     ]
    }
   ],
   "source": [
    "myepos = 20\n",
    "myreg = l2(0.01)\n",
    "hidden_nodes_iter = [[5,1],[10,1]]\n",
    "myactivators_iter = ['relu','sigmoid']\n",
    "for myhidden_nodes in hidden_nodes_iter:\n",
    "    print(\"================= tested DNN with layers : \", myhidden_nodes, \"==================\" )\n",
    "    scores = KerasCrossVal(A, B, myepos, myreg, myhidden_nodes, myactivators)\n",
    "    print(\"The cross validation accuracy is {:0.4f} ± {:0.4f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfLayout(num_layers, num_nodes, output_nodes, activators):\n",
    "    layoutconf = {}\n",
    "    for n_layers in num_layers:\n",
    "        \n",
    "        last_layer_nodes = [output_nodes]\n",
    "        output_activator = 'sigmoid' if output_nodes==1 else 'softmax'\n",
    "        \n",
    "        if n_layers == 0: # logistic regression\n",
    "            layoutconf[n_layer] = np.array(last_layer_nodes.reverse())\n",
    "            Activator = [output_activator]\n",
    "            \n",
    "        else: # at least one layer NN\n",
    "            for i_layer in range(1,n_layers+1):\n",
    "                if i_layer == 1:\n",
    "                    last_layer_nodes = last_layer_nodes * len(num_nodes)\n",
    "                    last_layer_nodes = [last_layer_nodes] + [num_nodes]\n",
    "                else:\n",
    "                    last_layer_nodes = [i*len(num_nodes) for i in last_layer_nodes]\n",
    "                    curr_layer_nodes = [val for val in num_nodes for _ in range(len(num_nodes)**(i_layer-1))]\n",
    "                    last_layer_nodes.append(curr_layer_nodes)\n",
    "            \n",
    "            Activator = [[i]*n_layers for i in activators]\n",
    "        \n",
    "        for i in range(len(Activator)):\n",
    "            Activator[i].append(output_activator)\n",
    "            \n",
    "        last_layer_nodes.reverse()\n",
    "        \n",
    "        layoutconf[n_layers] = {'layerconf': np.array(last_layer_nodes),\n",
    "                               'activatorconf': Activator}\n",
    "        \n",
    "    return layoutconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_layer_opts = [1, 2, 3]\n",
    "num_node_opts = [5, 20]\n",
    "output_nodes = 1\n",
    "activator_opts = ['relu', 'tanh']\n",
    "\n",
    "layerconfigall = ConfLayout(num_layer_opts, num_node_opts, output_nodes, activator_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activatorconf': [['relu', 'relu', 'relu', 'sigmoid'],\n",
       "  ['tanh', 'tanh', 'tanh', 'sigmoid']],\n",
       " 'layerconf': array([[ 5,  5,  5,  5, 20, 20, 20, 20],\n",
       "        [ 5,  5, 20, 20,  5,  5, 20, 20],\n",
       "        [ 5, 20,  5, 20,  5, 20,  5, 20],\n",
       "        [ 1,  1,  1,  1,  1,  1,  1,  1]])}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerconfigall[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  5,  5,  1])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerconfigall[3]['layerconf'][:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 1]], 'score(mean)': 0.87287376666791749, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.050029258346306359, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 1]], 'score(mean)': 0.78702899561464501, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.052673589795010987, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 1]], 'score(mean)': 0.76064893719210136, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0089913082318132508, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 1]], 'score(mean)': 0.92458641751456772, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0054804142171785966, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 1]], 'score(mean)': 0.8442141259848821, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.051584430366479327, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 1]], 'score(mean)': 0.76064871757906949, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0055298839740519426, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 1]], 'score(mean)': 0.92680765173861945, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.012207026859860274, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 1]], 'score(mean)': 0.86399017470513717, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.021700273644864564, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 1]], 'score(mean)': 0.76064885488798473, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0073743574150669927, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 1]], 'score(mean)': 0.93340200079400371, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.011779076464372616, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 1]], 'score(mean)': 0.86517684190303679, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.020645611219068948, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 1]], 'score(mean)': 0.76064877253530283, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0039740202104332732, 'nlayers': 1}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 1]], 'score(mean)': 0.77694564514142617, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.028570088072982967, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 1]], 'score(mean)': 0.76064880000239377, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.004905588926199105, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 1]], 'score(mean)': 0.76064940377488865, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0053692886842753819, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 1]], 'score(mean)': 0.84777012062522927, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.053469660823177612, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 1]], 'score(mean)': 0.76064866272437659, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0071580454593672951, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 1]], 'score(mean)': 0.7606494037219067, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0054604867548931806, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 1]], 'score(mean)': 0.79243901030213748, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.067414739653339537, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 1]], 'score(mean)': 0.79843596391518323, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.047660480718879197, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 1]], 'score(mean)': 0.76064858039817584, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0037664984028405448, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 1]], 'score(mean)': 0.89036521072228558, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.062646472173519388, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 1]], 'score(mean)': 0.78264863527494621, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.043724735713507025, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 1]], 'score(mean)': 0.76064737284436568, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.011773401547567406, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 1]], 'score(mean)': 0.92421623928574748, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0090893595617527936, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 1]], 'score(mean)': 0.76064844315989666, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0070069662138971377, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 1]], 'score(mean)': 0.76064923909600612, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.004759148826011507, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 1]], 'score(mean)': 0.92643950441381495, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0087154729418717977, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [[5, 20, 1]], 'score(mean)': 0.89139700574531222, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.018235550867995297, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 1]], 'score(mean)': 0.76064926648803133, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0093888889904995103, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 1]], 'score(mean)': 0.82184669218610651, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.078821077785506191, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 1]], 'score(mean)': 0.76064794920275802, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0079830812055539189, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 1]], 'score(mean)': 0.76064792172242313, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0096544923784978726, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 1]], 'score(mean)': 0.91480987474887066, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.012093978667518207, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 1]], 'score(mean)': 0.76064896465035881, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0057812718381756115, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 1]], 'score(mean)': 0.76064860786526689, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0061855202003742484, 'nlayers': 2}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 5, 1]], 'score(mean)': 0.76064772964270133, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.011813882709838325, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 5, 1]], 'score(mean)': 0.76064841576787801, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0070275037359690123, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 5, 1]], 'score(mean)': 0.760647564897593, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0095589103675552105, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 20, 1]], 'score(mean)': 0.76064844321730196, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0073322233437701605, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 20, 1]], 'score(mean)': 0.76064811384189579, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0067966298501677862, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 20, 1]], 'score(mean)': 0.76064830596136201, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0077160726422918907, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 5, 1]], 'score(mean)': 0.76064984291266236, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0071889269275762762, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 5, 1]], 'score(mean)': 0.76064904700745739, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0082798235538494962, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 5, 1]], 'score(mean)': 0.76064830593044452, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0058751342094174059, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 20, 1]], 'score(mean)': 0.7606484980896554, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0054094335463669213, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 20, 1]], 'score(mean)': 0.76064937629013696, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0049003255667272975, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 20, 1]], 'score(mean)': 0.7606485529796696, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0078560384333244623, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 5, 1]], 'score(mean)': 0.77598205096980144, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.028108495691927964, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 5, 1]], 'score(mean)': 0.76064852555232321, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0052642052539115594, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 5, 1]], 'score(mean)': 0.7606502820327754, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.010534512842102876, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 20, 1]], 'score(mean)': 0.76064948610106975, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.010522003475279644, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 20, 1]], 'score(mean)': 0.76065003501005113, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.010010677851865695, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 20, 1]], 'score(mean)': 0.76064995265736934, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.010861458531847629, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 5, 1]], 'score(mean)': 0.76064956848025234, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0064323690198859031, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [[20, 20, 5, 1]], 'score(mean)': 0.76064901952712893, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0043550285493839311, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 5, 1]], 'score(mean)': 0.76064923911366678, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0033846834404402354, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 20, 1]], 'score(mean)': 0.7873896230207571, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.058748628475359166, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 20, 1]], 'score(mean)': 0.76064877251544027, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0043936883027955991, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 20, 1]], 'score(mean)': 0.7606490194829677, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['relu', 'relu', 'relu', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0072147552889892542, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 5, 1]], 'score(mean)': 0.81747549849202483, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.071371516578483229, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 5, 1]], 'score(mean)': 0.76064885484824651, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0063293096362381455, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 5, 1]], 'score(mean)': 0.76064932146635511, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0098635320086497627, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 20, 1]], 'score(mean)': 0.82961563268926919, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.063482156643859713, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 20, 1]], 'score(mean)': 0.76064879998473323, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0050052430313045227, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 5, 20, 1]], 'score(mean)': 0.7606489645929535, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.011905287151018124, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 5, 1]], 'score(mean)': 0.76064951351517229, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.009631088793941367, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 5, 1]], 'score(mean)': 0.76064882745622131, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0084370934858442846, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 5, 1]], 'score(mean)': 0.7606490469853735, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0072252552388269043, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 20, 1]], 'score(mean)': 0.81517925705042149, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.075101889360840848, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 20, 1]], 'score(mean)': 0.76064918423689976, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.004909334120901292, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[5, 20, 20, 1]], 'score(mean)': 0.76064877253088592, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.005350919856380954, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 5, 1]], 'score(mean)': 0.7606490194829677, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0037085919259624068, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 5, 1]], 'score(mean)': 0.76064836089551813, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0053853670903257628, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 5, 1]], 'score(mean)': 0.76064775707888144, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.010076121869369277, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 20, 1]], 'score(mean)': 0.76064890972944021, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0029962460159213538, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 20, 1]], 'score(mean)': 0.76064819618573742, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0072883299075524616, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 5, 20, 1]], 'score(mean)': 0.76064948606133498, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.00585014683520034, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 5, 1]], 'score(mean)': 0.76064748261997062, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.012896339360096955, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 5, 1]], 'score(mean)': 0.76064836086461995, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0055459902761910707, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 5, 1]], 'score(mean)': 0.76064847066230901, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0073834835804606341, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 20, 1]], 'score(mean)': 0.76064932144428421, 'lr_reg': 0.001, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0036296058487689329, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [[20, 20, 20, 1]], 'score(mean)': 0.76064885491006851, 'lr_reg': 0.01, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0044078518994089943, 'nlayers': 3}\n",
      "====================== start new evaluation ================\n",
      "{'layers': [[20, 20, 20, 1]], 'score(mean)': 0.76064959592083603, 'lr_reg': 0.1, 'opt': 'Adam', 'activator': [['tanh', 'tanh', 'tanh', 'sigmoid']], 'lr_opt': 0.1, 'batch_size': 'default32', 'lr': 'l2', 'score(std)': 0.0047189557875356083, 'nlayers': 3}\n"
     ]
    }
   ],
   "source": [
    "myepos = 200\n",
    "lr_reg = [0.001, 0.01, 0.1] \n",
    "reg_opts = [l2(i) for i in lr_reg]\n",
    "\n",
    "### need to be implemented:\n",
    "# myopt = Adame(lr=lr_opt[i])\n",
    "# batch_size = 32, ...\n",
    "# decay\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "for nlayer in num_layer_opts:\n",
    "    for myactivators in layerconfigall[nlayer]['activatorconf']:\n",
    "        for i in range(layerconfigall[nlayer]['layerconf'].shape[1]):\n",
    "            myhidden_nodes = layerconfigall[nlayer]['layerconf'][:,i].tolist()\n",
    "            for myreglr in lr_reg:  \n",
    "                myreg = l2(myreglr)\n",
    "                print('====================== start new evaluation ================')\n",
    "                scores = KerasCrossVal(A, B, myepos, myreg, myhidden_nodes, myactivators)\n",
    "\n",
    "                d = {'nlayers':nlayer,'layers':[myhidden_nodes],'activator':[myactivators],\n",
    "                     'lr':'l2','lr_reg':myreglr,\n",
    "                     'opt':'Adam','lr_opt':0.1,\n",
    "                     'batch_size':'default32',\n",
    "                     'score(mean)': scores.mean(),'score(std)': scores.std()}\n",
    "                df_result = pd.concat([df_result, pd.DataFrame(d)])\n",
    "                \n",
    "                print(d) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
