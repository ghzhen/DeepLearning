{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data('/tmp/mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121d9bd30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0H9H4BpmwJXvvG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121d1b240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.fit(X_train, y_train_cat, batch_size=128, epochs=10, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test_cat)[1]\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.random.randint(10, size=(2, 3, 4, 5))\n",
    "B = np.random.randint(10, size=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0, 1, 0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 8],\n",
       "       [8, 0, 5]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A random colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[242,  59, 220],\n",
       "        [ 54, 223, 149],\n",
       "        [ 57, 228, 237],\n",
       "        [189, 248, 209]],\n",
       "\n",
       "       [[249,  65,   8],\n",
       "        [ 83,   8, 143],\n",
       "        [ 18, 157, 102],\n",
       "        [200,  47, 160]],\n",
       "\n",
       "       [[162,  66,  68],\n",
       "        [211, 235,  26],\n",
       "        [172,   0, 171],\n",
       "        [116, 134,   9]],\n",
       "\n",
       "       [[126,  23,  13],\n",
       "        [208, 190, 109],\n",
       "        [  4, 200, 203],\n",
       "        [ 54,  89, 196]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.randint(255, size=(4, 4, 3), dtype='uint8')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1295c9c18>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAE/CAYAAAAqmiQlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZJcJiZWRL+P4Uyl9UTZY5KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f938128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img)\n",
    "plt.title(\"All Channels combined\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(img[:, : , 0], cmap='Reds')\n",
    "plt.title(\"Red channel\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(img[:, : , 1], cmap='Greens')\n",
    "plt.title(\"Green channel\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(img[:, : , 2], cmap='Blues')\n",
    "plt.title(\"Blue channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 2,  6, 18, 16,  4],\n",
       "         [ 8, 16, 16, 18,  8],\n",
       "         [ 2,  4,  8,  0,  4],\n",
       "         [16, 18,  4, 18,  0]],\n",
       "\n",
       "        [[ 8, 12,  2, 16, 14],\n",
       "         [ 0,  8,  0, 12,  4],\n",
       "         [14,  4, 14, 12,  8],\n",
       "         [12,  6,  2,  0, 16]],\n",
       "\n",
       "        [[12, 14, 14, 18,  2],\n",
       "         [ 6,  8, 16, 18, 10],\n",
       "         [ 2, 16,  2,  2, 12],\n",
       "         [10, 18, 18, 14,  8]]],\n",
       "\n",
       "\n",
       "       [[[ 8, 12,  6, 12,  0],\n",
       "         [18,  4,  6, 12, 14],\n",
       "         [14,  0, 16, 10, 14],\n",
       "         [ 4, 12, 16,  4,  8]],\n",
       "\n",
       "        [[14,  4,  2,  0,  8],\n",
       "         [18,  0,  2, 16, 16],\n",
       "         [12,  6, 16,  4, 12],\n",
       "         [ 4, 14, 10,  4, 14]],\n",
       "\n",
       "        [[10,  4, 16, 18, 12],\n",
       "         [14,  2,  2, 10,  0],\n",
       "         [10, 10, 12, 10, 18],\n",
       "         [ 4, 18, 18, 18, 18]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 2,  6, 18, 16,  4],\n",
       "         [ 8, 16, 16, 18,  8],\n",
       "         [ 2,  4,  8,  0,  4],\n",
       "         [16, 18,  4, 18,  0]],\n",
       "\n",
       "        [[ 8, 12,  2, 16, 14],\n",
       "         [ 0,  8,  0, 12,  4],\n",
       "         [14,  4, 14, 12,  8],\n",
       "         [12,  6,  2,  0, 16]],\n",
       "\n",
       "        [[12, 14, 14, 18,  2],\n",
       "         [ 6,  8, 16, 18, 10],\n",
       "         [ 2, 16,  2,  2, 12],\n",
       "         [10, 18, 18, 14,  8]]],\n",
       "\n",
       "\n",
       "       [[[ 8, 12,  6, 12,  0],\n",
       "         [18,  4,  6, 12, 14],\n",
       "         [14,  0, 16, 10, 14],\n",
       "         [ 4, 12, 16,  4,  8]],\n",
       "\n",
       "        [[14,  4,  2,  0,  8],\n",
       "         [18,  0,  2, 16, 16],\n",
       "         [12,  6, 16,  4, 12],\n",
       "         [ 4, 14, 10,  4, 14]],\n",
       "\n",
       "        [[10,  4, 16, 18, 12],\n",
       "         [14,  2,  2, 10,  0],\n",
       "         [10, 10, 12, 10, 18],\n",
       "         [ 4, 18, 18, 18, 18]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109, 126, 156, 197,  46],\n",
       "       [147,  85, 125, 181, 112],\n",
       "       [ 93,  97, 118,  73, 157],\n",
       "       [ 98, 201, 189, 153, 109]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tensordot(A, B, axes=([0, 1], [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tensordot(A, B, axes=([0], [0])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.array([-1, 1], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.convolve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(a, 'o-')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(c, 'o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image filters with convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import convolve\n",
    "from scipy.signal import convolve2d\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = misc.ascent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_kernel = np.array([[ 1,  2,  1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [-1, -2, -1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(h_kernel, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = convolve2d(img, h_kernel)\n",
    "\n",
    "plt.imshow(res, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_tensor = img.reshape((1, 512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), strides=(2,1), input_shape=(512, 512, 1)))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred_tensor = model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred = img_pred_tensor[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(weights[0][:, :, 0, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights[0] = np.ones(weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred_tensor = model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred = img_pred_tensor[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), input_shape=(512, 512, 1), padding='same'))\n",
    "model.compile('adam', 'mse')\n",
    "\n",
    "img_pred_tensor = model.predict(img_tensor)\n",
    "\n",
    "\n",
    "img_pred_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPool2D, AvgPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(MaxPool2D((5, 5), input_shape=(512, 512, 1)))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred = model.predict(img_tensor)[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(AvgPool2D((5, 5), input_shape=(512, 512, 1)))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_pred = model.predict(img_tensor)[0, :, :, 0]\n",
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train_cat, batch_size=128,\n",
    "          epochs=2, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 1\n",
    "You've been hired by a shipping company to overhaul the way they route mail, parcels and packages. They want to build an image recognition system  capable of recognizing the digits in the zipcode on a package, so that it can be automatically routed to the correct location.\n",
    "You are tasked to build the digit recognition system. Luckily, you can rely on the MNIST dataset for the intial training of your model!\n",
    "\n",
    "Build a deep convolutional neural network with at least two convolutional and two pooling layers before the fully connected layer.\n",
    "\n",
    "- Start from the network we have just built\n",
    "- Insert a `Conv2D` layer after the first `MaxPool2D`, give it 64 filters.\n",
    "- Insert a `MaxPool2D` after that one\n",
    "- Insert an `Activation` layer\n",
    "- retrain the model\n",
    "- does performance improve?\n",
    "- how many parameters does this new model have? More or less than the previous model? Why?\n",
    "- how long did this second model take to train? Longer or shorter than the previous model? Why?\n",
    "- did it perform better or worse than the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Pleased with your performance with the digits recognition task, your boss decides to challenge you with a harder task. Their online branch allows people to upload images to a website that generates and prints a postcard that is shipped to destination. Your boss would like to know what images people are loading on the site in order to provide targeted advertising on the same page, so he asks you to build an image recognition system capable of recognizing a few objects. Luckily for you, there's a dataset ready made with a collection of labeled images. This is the [Cifar 10 Dataset](http://www.cs.toronto.edu/~kriz/cifar.html), a very famous dataset that contains images for 10 different categories:\n",
    "\n",
    "- airplane \t\t\t\t\t\t\t\t\t\t\n",
    "- automobile \t\t\t\t\t\t\t\t\t\t\n",
    "- bird \t\t\t\t\t\t\t\t\t\t\n",
    "- cat \t\t\t\t\t\t\t\t\t\t\n",
    "- deer \t\t\t\t\t\t\t\t\t\t\n",
    "- dog \t\t\t\t\t\t\t\t\t\t\n",
    "- frog \t\t\t\t\t\t\t\t\t\t\n",
    "- horse \t\t\t\t\t\t\t\t\t\t\n",
    "- ship \t\t\t\t\t\t\t\t\t\t\n",
    "- truck\n",
    "\n",
    "In this exercise we will reach the limit of what you can achieve on your laptop and get ready for the next session on cloud GPUs.\n",
    "\n",
    "Here's what you have to do:\n",
    "- load the cifar10 dataset using `keras.datasets.cifar10.load_data()`\n",
    "- display a few images, see how hard/easy it is for you to recognize an object with such low resolution\n",
    "- check the shape of X_train, does it need reshape?\n",
    "- check the scale of X_train, does it need rescaling?\n",
    "- check the shape of y_train, does it need reshape?\n",
    "- build a model with the following architecture, and choose the parameters and activation functions for each of the layers:\n",
    "    - conv2d\n",
    "    - conv2d\n",
    "    - maxpool\n",
    "    - conv2d\n",
    "    - conv2d\n",
    "    - maxpool\n",
    "    - flatten\n",
    "    - dense\n",
    "    - output\n",
    "- compile the model and check the number of parameters\n",
    "- attempt to train the model with the optimizer of your choice. How fast does training proceed?\n",
    "- If training is too slow (as expected) stop the execution and move to the next session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
